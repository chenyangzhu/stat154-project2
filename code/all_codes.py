# -*- coding: utf-8 -*-
"""project2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nb6Nz66YzVM6qbOL8etQ_HaYAdoV1zc2

# Cloud Detection with Bancroft Model
### Flying Ramen Pok√©mon
Chenyang Zhu and Ling Xie, UC Berkeley

# Section 1.  Data Collection and Exploration

## 1. Import packages and read data
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from random import shuffle
import sklearn.linear_model
import sklearn.discriminant_analysis
import sklearn.ensemble
import sklearn.svm
import sklearn.model_selection

"""read in raw data provided in Shi et al. [2018]"""

img1 = pd.read_csv("./img1.csv", index_col=0)
img2 = pd.read_csv("./img2.csv", index_col=0)
img3 = pd.read_csv("./img3.csv", index_col=0)

"""Change column name for later user"""

col_names = ['x', 'y', 'label', 'NDAI', 'SD', 'CORR','DF','CF','BF','AF','AN']
img1.columns = col_names
img2.columns = col_names
img3.columns = col_names

"""Delete 0 point for unlabeled data. We are not going to use these data."""

img1 = img1[img1['label'] != 0.0]
img1_n = int(len(img1) * 0.8)
img2 = img2[img2['label'] != 0.0]
img2_n = int(len(img2) * 0.8)
img3 = img3[img3['label'] != 0.0]
img3_n = int(len(img3) * 0.8)

"""Concatenate into a large dataset."""

data =  pd.concat([img1, img2])
data = pd.concat([data, img3])

"""## 2. Data Exploration

The padded images are located in `./data/pads`
"""

plt.figure(figsize=(15,60))

plt.subplot(1,4,1)
plt.imshow(img1_pad, cmap = "gist_gray")
plt.axis('off')
plt.subplot(1,4,2)
plt.imshow(img1_pad_ndai, cmap="Blues")
plt.axis('off')
plt.subplot(1,4,3)
plt.imshow(img1_pad_corr,cmap='pink')
plt.axis('off')
plt.subplot(1,4,4)
plt.imshow(img1_pad_sd, cmap = "summer")
plt.axis('off')

# White is cloud

plt.figure(figsize=(15,60))

plt.subplot(1,4,1)
plt.imshow(img2_pad, cmap = "gist_gray")
plt.axis('off')
plt.subplot(1,4,2)
plt.imshow(img2_pad_ndai, cmap="Blues")
plt.axis('off')
plt.subplot(1,4,3)
plt.imshow(img2_pad_corr,cmap='pink')
plt.axis('off')
plt.subplot(1,4,4)
plt.imshow(img2_pad_sd, cmap = "summer")
plt.axis('off')

plt.figure(figsize=(15,60))

plt.subplot(1,4,1)
plt.imshow(img3_pad, cmap = "gist_gray")
plt.axis('off')
plt.subplot(1,4,2)
plt.imshow(img3_pad_ndai, cmap="Blues")
plt.axis('off')
plt.subplot(1,4,3)
plt.imshow(img3_pad_corr,cmap='pink')
plt.axis('off')
plt.subplot(1,4,4)
plt.imshow(img3_pad_sd, cmap = "summer")
plt.axis('off')

"""## 3. Visual and Qualitative EDA"""

sns.heatmap(data.loc[:, data.columns != 'label'].corr(), \
            cmap="YlGnBu", annot=True).set_title('Pairwise correlation between features')

sns.heatmap(data.corr().iloc[2:3, [0,1,3,4,5,6,7,8,9,10]], \
            cmap="YlGnBu", annot=True,cbar_kws={"orientation": "horizontal"}).\
set_title('Correlation Heatmap between Lables and Features')

sns.boxplot(x="label", y="NDAI", data=data).\
set_title('Boxplot of NDAI with respect to cloudiness')

sns.boxplot(x="label", y="AF", data=data).\
set_title('Boxplot of AF with respect to cloudiness')

"""The boxplot shown above illustrates the difference in the distribution of NDAI with respect to cloudiness. For pixels labelled as cloudiness, they generally have higher NDAIs compared to those labelled as cloud-free and a larger range of possible values of NDAIs.

# Section 2. Preparation

## 1. Split Data

We consider two data split methods.

### Split Method #1

The first method is to do proportional sampling on each image has the same representationin each set.  To do this, we randomly shuffle the pixels in each image and split each image into threesets, each for train, valid and test.  Finally we combine the three images together.
"""

def split1(img):
  # For 1
  subset = img[img['label'] == 1]
  subset = subset.sample(frac=1)
  len_subset = len(subset)
  
  train = subset.iloc[:int(len_subset*0.6)]
  val = subset.iloc[int(len_subset*0.6):int(len_subset*0.8)]
  test = subset.iloc[int(len_subset*0.8):]
  
  # For -1
  subset = img[img['label'] == -1]
  subset = subset.sample(frac=1)
  len_subset = len(subset)
  
  train = pd.concat([train,subset.iloc[:int(len_subset*0.6)]])
  val = pd.concat([val,subset.iloc[int(len_subset*0.6):int(len_subset*0.8)]])
  test = pd.concat([test,subset.iloc[int(len_subset*0.8):]])
  
  return train, val, test

img1_train, img1_val, img1_test = split1(img1)
img2_train, img2_val, img2_test = split1(img2)
img3_train, img3_val, img3_test = split1(img3)

train_1 = pd.concat([img1_train,img2_train,img3_train])
val_1 = pd.concat([img1_val,img2_val,img3_val])
test_1 = pd.concat([img1_test,img2_test,img3_test])

train_1 = train_1.sample(frac=1)
test_1 = test_1.sample(frac=1)
val_1 = val_1.sample(frac=1)

train_feat_1 = train_1.loc[:, train_1.columns != 'label']
train_label_1 = train_1['label']

val_feat_1 = val_1.loc[:, val_1.columns != 'label']
val_label_1 = val_1['label']

# train_feat_1 = pd.concat([train_feat_1, val_feat_1])
# train_label_1 = pd.concat([train_label_1, val_label_1])

test_feat_1 = test_1.loc[:, test_1.columns != 'label']
test_label_1 = test_1['label']

"""### Split Method #2

Considering the spatial dependence of the image pixels, we decided not to do random shuffling. Instead, in order the preserve the spatial pattern, we split the data based on the sequential order: first 60% of the data (rows in the dataset) in each image constitutes the training set, the following 20% goes to validation set and the last 20% will be used for testing.
"""

train_2 = img1.iloc[:int(img1.shape[0] * 0.6),:]
train_2 = pd.concat([train_2, img2.iloc[:int(img2.shape[0] * 0.6),:]])
train_2 = pd.concat([train_2, img3.iloc[:int(img3.shape[0] * 0.6),:]])
train_2.index = range(len(train_2))

valid_2 = img1.iloc[int(img1.shape[0] * 0.6):int(img1.shape[0] * 0.8),:]
valid_2 = pd.concat([valid_2, img2.iloc[int(img2.shape[0] * 0.6):int(img2.shape[0] * 0.8),:]])
valid_2 = pd.concat([valid_2, img3.iloc[int(img3.shape[0] * 0.6):int(img3.shape[0] * 0.8),:]])
valid_2.index = range(len(valid_2))

train_valid_2 = pd.concat([train_2, valid_2])
train_valid_2.index = range(len(train_valid_2))

test_2 = img1.iloc[int(img1.shape[0] * 0.8):,:]
test_2 = pd.concat([test_2, img2.iloc[int(img2.shape[0] * 0.8):,:]])
test_2 = pd.concat([test_2, img3.iloc[int(img3.shape[0] * 0.8):,:]])
test_2.index = range(len(test_2))

train_feat_2 = train_2.loc[:, train_2.columns != 'label']
train_label_2 = train_2['label']

valid_feat_2 = valid_2.loc[:, valid_2.columns != 'label']
valid_label_2 = valid_2['label']

test_feat_2 = test_2.loc[:, test_2.columns != 'label']
test_label_2 = test_2['label']

"""## 2. Baseline Accuracy"""

def baseline_classifier(test_feat):
  return np.repeat(-1, len(test_feat))

baseline_accuracy = np.sum(baseline_classifier(test_feat_2) == test_label_2) + \
np.sum(baseline_classifier(valid_feat_2) == valid_label_2)

baseline_accuracy =  baseline_accuracy / (len(test_feat_2) + len(valid_feat_2))
print('The baseline accuracy is ' + str(round(baseline_accuracy,3)))

"""For Split 1"""

baseline_train_1 = np.mean(train_label_1 == -1)
baseline_test_1 = np.mean(test_label_1 == -1)
baseline_val_1 = np.mean(val_label_1 == -1)
print((baseline_train_1, baseline_val_1, baseline_test_1))

"""For Split 2"""

baseline_train_2 = np.mean(train_label_2 == -1)
baseline_test_2 = np.mean(test_label_2 == -1)
baseline_valid_2 = np.mean(valid_label_2 == -1)
print((baseline_train_2, baseline_valid_2, baseline_test_2))

"""## 4. CV Generic"""

import time
def CVGeneric(classifier, img_train, K, loss_func, cvsplit_method, \
              img1_n =  img1_n, img2_n = img2_n, img3_n = img3, **kwargs):
  # Input:
    # Classifier:     function    some classifier
    # img:            dataframe   training X matrix  and labels
    # K:              int         K-fold CV
    # loss_func:      function    some loss function
  # Output:
    # K-fold CV loss  float       loss

  cv_label = cvsplit_method(img_train, K, img1_n, img2_n, img3_n)
  # print(cv_label)
  val_acc = []
  loss = []
  
  # Change img_train indexing for logistic models
  img = img_train.copy()
  img['label'] = np.where(img['label'] == -1.0, 0.0,1.0)
  start = time.time()
  for k in range(K):
    # CV Training data
    img_cvval = img.loc[cv_label[k]]
    img_cvtrain = img.drop(cv_label[k])

    # Use the remaining cv_label to test
    # print(img_cvval['label'])
    # print(img_cvtrain['label'])
    predictions = classifier(img_cvtrain, img_cvval, **kwargs)
    
#     print(predictions)
#     print(img_cvval['label'])

    val_acc.append(np.mean(predictions == img_cvval['label']))
    # val_acc[k] <- sum(abs(predictions - img.cvval$label)) / nrow(img.cvval)
    loss.append(loss_func(predictions, img_cvval['label']))
  print("--- %s seconds ---" % (time.time() - start))
  outcome = {}
  outcome['val_acc'] = val_acc
  outcome['loss'] = loss
  
  return outcome

"""### Loss Function"""

def default_loss(y_hat,y):
#   print(y)
#   print(y_hat)
  return sklearn.metrics.log_loss(y, y_hat)
#   return np.sum(np.abs(y_hat-y))/len(y)

"""### Classifiers"""

FEATURE = ['CORR','NDAI','SD', 'DF','CF','BF','AF','AN']

def logistic(train, val, **kwargs):
  '''
  Need to input threshod
  '''
  threshold = kwargs["threshold"]
  model = sklearn.linear_model.LogisticRegression()
  model.fit(train[FEATURE], train['label'])
  prediction = model.predict(val[FEATURE])
  prediction = np.where(prediction > threshold, 1, 0)
  return prediction

def LDA(train, val):
  '''
  https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html
  '''
  model = sklearn.discriminant_analysis.LinearDiscriminantAnalysis()
  model.fit(train[FEATURE], train['label'])
  prediction = model.predict(val[FEATURE])
  return prediction

def QDA(train, val):
  '''
  https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.html
  '''
  model = sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis()
  model.fit(train[FEATURE], train['label'])
  prediction = model.predict(val[FEATURE])
  return prediction

def randomforest(train, val, **kwargs):
  '''
  https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html
  need to inpu n_estimators=100, max_depth=2 in CVgeneric
  '''
  n_estimators = kwargs['n_estimators']
  max_depth = kwargs['max_depth']
  
  model = sklearn.ensemble.RandomForestClassifier(n_estimators=n_estimators,
                                                  max_depth=max_depth,
                                                  random_state=0)
  model.fit(train[FEATURE], train['label'])
  prediction = model.predict(val[FEATURE])
  return prediction

def SVM(train, val,**kwargs):
  '''
  Need to input kernel='rbf' in CVgeneric
  '''
  kernel = kwargs['kernel']
  model = sklearn.svm.SVC(kernel = kernel)
  model.fit(train[FEATURE], train['label'])
  prediction = model.predict(val[FEATURE])
  return prediction

"""### Split Method"""

def cv_split_1(img, K, img1_n, img2_n, img3_n):
  
  img_cvlist = [[] for _ in range(K)]
  
  for i in [-1,1]:
    img_specific = img[img['label'] == i]
    idx = list(img_specific.index)
    shuffle(idx)
    
    chunk_size = int(len(idx) / K)

    for k in range(K):
      
      start = chunk_size * k      
      end = chunk_size * (k+1)-1
      img_k = idx[start:end]
      img_cvlist[k].extend(img_k)
        
  return img_cvlist

def cv_split_2(train, k, img1_n, img2_n, img3_n):
  
  indices = [[] for _ in range(k)]
  img1_sub_size = int(img1_n / k)
  img2_sub_size = int(img2_n / k)
  img3_sub_size = int(img3_n / k)
  
#   img1_endpoint = 0
#   img2_endpoint = img1_n
#   img3_endpoint = img1_n + img2_n
  img1_start, img2_start, img3_start = 0, 0, 0
  
  for i in range(1, k+1):
    if i != k:
      indices[i-1].extend(range(img1_start, img1_start + img1_sub_size))
      indices[i-1].extend(range(img2_start, img2_start + img2_sub_size))
      indices[i-1].extend(range(img3_start, img3_start + img3_sub_size))
    else:
      indices[i-1].extend(range(img1_start, img1_n))
      indices[i-1].extend(range(img2_start, img2_n))
      indices[i-1].extend(range(img3_start, img3_n))
      
    img1_start += img1_sub_size
    img2_start += img2_sub_size
    img3_start += img3_sub_size
  
  return indices

"""# Section 3.  Modeling

## 1. Modeling and Accuracy
"""

log_1 = CVGeneric(logistic, pd.concat([train_1,val_1]), 10, default_loss, \
                  cv_split_1,threshold = 0.3)

rf_1 = CVGeneric(randomforest, pd.concat([train_1,val_1]), 10, default_loss,\
                 cv_split_1,n_estimators=100, max_depth=20, max_features = 8)

LDA_1 = CVGeneric(LDA, pd.concat([train_1,val_1]), 10, default_loss, cv_split_1)

QDA_1 = CVGeneric(QDA, pd.concat([train_1,val_1]), 10, default_loss, cv_split_1)

log_2 = CVGeneric(logistic, train_valid_2, 10, default_loss, cv_split_2, \
                  img1_n, img2_n, img3_n, threshold = 0.3)
rf_2 = CVGeneric(randomforest, train_valid_2, 10, default_loss, cv_split_2, \
                 img1_n, img2_n, img3_n, n_estimators=100, max_depth=20, \
                 max_features = 8)
LDA_2 = CVGeneric(LDA, train_valid_2, 10, default_loss, cv_split_2, \
                  img1_n, img2_n, img3_n)
QDA_2 = CVGeneric(QDA, train_valid_2, 10, default_loss, cv_split_2, \
                  img1_n, img2_n, img3_n)

print(log_1)
print(rf_1)
print(LDA_1)
print(QDA_1)

print(np.mean(log_1['val_acc']))
print(np.mean(rf_1['val_acc']))
print(np.mean(LDA_1['val_acc']))
print(np.mean(QDA_1['val_acc']))

print(log_2)
print(rf_2)
print(LDA_2)
print(QDA_2)

print(np.mean(log_2['val_acc']))
print(np.mean(rf_2['val_acc']))
print(np.mean(LDA_2['val_acc']))
print(np.mean(QDA_2['val_acc']))

test_all = pd.concat([test_1, test_2])
test_all.drop_duplicates(subset = ['x', 'y', 'SD', 'NDAI','AF'], 
                     keep = 'first', inplace = True)
test_all_labels = test_all['label']
test_all_feat = test_all[FEATURE]

val_all = pd.concat([val_1, valid_2])
val_all.drop_duplicates(subset = ['x', 'y', 'SD', 'NDAI','AF'], 
                     keep = 'first', inplace = True)
val_all_labels = val_all['label']
val_all_feat = val_all[FEATURE]

y_true = np.where(test_all_labels == -1.0, 0.0,1.0)
logistic_model_1 = sklearn.linear_model.LogisticRegression()
logistic_model_1.fit(train_1[FEATURE], train_1['label'])
logistic_pred_1 = logistic_model_1.predict(test_all[FEATURE])
logistic_pred_1 = np.where(logistic_pred_1 > 0.3, 1, 0)
log_acc_1 = np.mean(logistic_pred_1 == y_true)

logistic_model_2 = sklearn.linear_model.LogisticRegression()
logistic_model_2.fit(train_2[FEATURE], train_2['label'])
logistic_pred_2 = logistic_model_2.predict(test_all[FEATURE])
logistic_pred_2 = np.where(logistic_pred_2 > 0.3, 1, 0)
log_acc_2 = np.mean(logistic_pred_2 == y_true)

print('Logistic Model for splitting method 1: ')
print(log_acc_1)

print('Logistic Model for splitting method 2: ')
print(log_acc_2)

rf_model_1 = sklearn.ensemble.RandomForestClassifier(n_estimators=100,
                                                  max_depth=20,
                                                  random_state=0)
rf_model_1.fit(train_1[FEATURE], train_1['label'])
rf_pred_1 = rf_model_1.predict(test_all[FEATURE])
rf_acc_1 = np.mean(rf_pred_1 == test_all_labels)

rf_model_2 = sklearn.ensemble.RandomForestClassifier(n_estimators=100,
                                                  max_depth=20,
                                                  random_state=0)
rf_model_2.fit(train_2[FEATURE], train_2['label'])
rf_pred_2 = rf_model_2.predict(test_all[FEATURE])
rf_acc_2 = np.mean(rf_pred_2 == test_all_labels)

print('Random Forest for splitting method 1: ')
print(rf_acc_1)

print('Random Forset for splitting method 2: ')
print(rf_acc_2)

lda_model_1 = sklearn.discriminant_analysis.LinearDiscriminantAnalysis()
lda_model_1.fit(train_1[FEATURE], train_1['label'])
lda_pred_1 = lda_model_1.predict(test_all[FEATURE])
lda_acc_1 = np.mean(lda_pred_1 == test_all_labels)

lda_model_2 = sklearn.discriminant_analysis.LinearDiscriminantAnalysis()
lda_model_2.fit(train_2[FEATURE], train_2['label'])
lda_pred_2 = lda_model_2.predict(test_all[FEATURE])
lda_acc_2 = np.mean(lda_pred_2 == test_all_labels)

print('LDA for splitting method 1: ')
print(lda_acc_1)

print('LDA for splitting method 2: ')
print(lda_acc_2)

qda_model_1 = sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis()
qda_model_1.fit(train_1[FEATURE], train_1['label'])
qda_pred_1 = qda_model_1.predict(test_all[FEATURE])
qda_acc_1 = np.mean(qda_pred_1 == test_all_labels)

qda_model_2 = sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis()
qda_model_2.fit(train_2[FEATURE], train_2['label'])
qda_pred_2 = qda_model_2.predict(test_all[FEATURE])
qda_acc_2 = np.mean(qda_pred_2 == test_all_labels)

print('QDA for splitting method 1: ')
print(qda_acc_1)

print('QDA for splitting method 2: ')
print(qda_acc_2)

"""## 2. ROC Curve

###  Use split 1
"""

import sklearn.metrics

FEATURE = ['NDAI',
 'SD',
 'CORR',
 'DF',
 'CF',
 'BF',
 'AF',
 'AN']

fpr_list = []
tpr_list = []
threshold_list = []
auc_list = []


#LDA
print("LDA")
model = sklearn.discriminant_analysis.LinearDiscriminantAnalysis()
model.fit(train_1[FEATURE], train_1['label'])
score = model.predict_proba(test_1[FEATURE])
fpr, tpr, threshold = sklearn.metrics.roc_curve(test_1['label'], score[:,1])
auc = sklearn.metrics.roc_auc_score(test_1['label'], score[:,1])
fpr_list.append(fpr)
tpr_list.append(tpr)
threshold_list.append(threshold)
auc_list.append(auc)


# LR
print("LR")
model = sklearn.linear_model.LogisticRegression()
model.fit(train_1[FEATURE], train_1['label'])
score = model.predict_proba(test_1[FEATURE])
fpr, tpr, threshold = sklearn.metrics.roc_curve(test_1['label'], score[:,1])
auc = sklearn.metrics.roc_auc_score(test_1['label'], score[:,1])

fpr_list.append(fpr)
tpr_list.append(tpr)
threshold_list.append(threshold)
auc_list.append(auc)


# QDA
print("QDA")
model = sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis()
model.fit(train_1[FEATURE], train_1['label'])
score = model.predict_proba(test_1[FEATURE])
fpr, tpr, threshold = sklearn.metrics.roc_curve(test_1['label'], score[:,1])
auc = sklearn.metrics.roc_auc_score(test_1['label'], score[:,1])

fpr_list.append(fpr)
tpr_list.append(tpr)
threshold_list.append(threshold)
auc_list.append(auc)


# SVM
# print("SVM")
# model = sklearn.svm.SVC(kernel = 'rbf',probability=True)
# model.fit(train_1[FEATURE], train_1['label'])
# score = model.predict_proba(test_1[FEATURE])
# fpr, tpr, threshold = sklearn.metrics.roc_curve(test_1['label'], score[:,1])
# auc = sklearn.metrics.roc_auc_score(test_1['label'], score[:,1])
# fpr_list.append(fpr)
# tpr_list.append(tpr)
# threshold_list.append(threshold)
# auc_list.append(auc)


print("RF")
# RF
model = sklearn.ensemble.RandomForestClassifier(n_estimators=100,
                                                  max_depth=20,
                                                  random_state=0)
model.fit(train_1[FEATURE], train_1['label'])
score = model.predict_proba(test_1[FEATURE])
fpr, tpr, threshold = sklearn.metrics.roc_curve(test_1['label'], score[:,1])
auc = sklearn.metrics.roc_auc_score(test_1['label'], score[:,1])

fpr_list.append(fpr)
tpr_list.append(tpr)
threshold_list.append(threshold)
auc_list.append(auc)

optimal_threshold_list = []

for i in range(4):
  optimal_idx = np.argmax(tpr_list[i] - fpr_list[i])
  optimal_threshold = threshold_list[i][optimal_idx]
  optimal_threshold_list.append(optimal_threshold)

optimal_idx_list = []

for i in range(4):
  optimal_idx = np.argmax(tpr_list[i] - fpr_list[i])
  optimal_idx_list.append(optimal_idx)

name_list = ["LDA","Log-Reg","QDA","Rand-Forest"]
color_list = ["blue","green","gold","brown"]
plt.figure(figsize=(18,4))


plt.subplot(141)
plt.bar(name_list,optimal_threshold_list, color=color_list, alpha = 0.8)
plt.title("Threshold")

plt.subplot(142)
for i in range(4):
  plt.plot(fpr_list[i],tpr_list[i],label=name_list[i], c=color_list[i])
  plt.scatter(fpr_list[i][optimal_idx_list[i]],tpr_list[i][optimal_idx_list[i]],marker='o', c=color_list[i])
plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('ROC curve')
plt.legend(loc='best')
plt.plot([0, 1], [0, 1], '--')

plt.subplot(143)
for i in range(4):
  plt.plot(fpr_list[i],tpr_list[i],label=name_list[i], c=color_list[i])
  plt.scatter(fpr_list[i][optimal_idx_list[i]],tpr_list[i][optimal_idx_list[i]],marker='o', c=color_list[i])
plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.ylim(0.8,1.0)
plt.xlim(0,0.2)
plt.title('ROC curve zoomed in')
plt.legend(loc='best')

plt.subplot(144)
plt.bar(name_list,auc_list, color=color_list, alpha = 0.8)
plt.title("AUC score")
plt.ylim(0.94,1)

plt.subplots_adjust(wspace=0.25)

"""### Use split 2"""

FEATURE = ['NDAI',
 'SD',
 'CORR',
 'DF',
 'CF',
 'BF',
 'AF',
 'AN']

fpr_list = []
tpr_list = []
threshold_list = []
auc_list = []


#LDA
print("LDA")
model = sklearn.discriminant_analysis.LinearDiscriminantAnalysis()
model.fit(train_2[FEATURE], train_2['label'])
score = model.predict_proba(test_2[FEATURE])
fpr, tpr, threshold = sklearn.metrics.roc_curve(test_2['label'], score[:,1])
auc = sklearn.metrics.roc_auc_score(test_2['label'], score[:,1])
fpr_list.append(fpr)
tpr_list.append(tpr)
threshold_list.append(threshold)
auc_list.append(auc)


# LR
print("LR")
model = sklearn.linear_model.LogisticRegression()
model.fit(train_2[FEATURE], train_2['label'])
score = model.predict_proba(test_2[FEATURE])
fpr, tpr, threshold = sklearn.metrics.roc_curve(test_2['label'], score[:,1])
auc = sklearn.metrics.roc_auc_score(test_2['label'], score[:,1])

fpr_list.append(fpr)
tpr_list.append(tpr)
threshold_list.append(threshold)
auc_list.append(auc)


# QDA
print("QDA")
model = sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis()
model.fit(train_2[FEATURE], train_2['label'])
score = model.predict_proba(test_2[FEATURE])
fpr, tpr, threshold = sklearn.metrics.roc_curve(test_2['label'], score[:,1])
auc = sklearn.metrics.roc_auc_score(test_2['label'], score[:,1])

fpr_list.append(fpr)
tpr_list.append(tpr)
threshold_list.append(threshold)
auc_list.append(auc)


# SVM
# print("SVM")
# model = sklearn.svm.SVC(kernel = 'rbf',probability=True)
# model.fit(train_1[FEATURE], train_1['label'])
# score = model.predict_proba(test_1[FEATURE])
# fpr, tpr, threshold = sklearn.metrics.roc_curve(test_1['label'], score[:,1])
# auc = sklearn.metrics.roc_auc_score(test_1['label'], score[:,1])
# fpr_list.append(fpr)
# tpr_list.append(tpr)
# threshold_list.append(threshold)
# auc_list.append(auc)


print("RF")
# RF
model = sklearn.ensemble.RandomForestClassifier(n_estimators=100,
                                                  max_depth=20,
                                                  random_state=0)
model.fit(train_2[FEATURE], train_2['label'])
score = model.predict_proba(test_2[FEATURE])
fpr, tpr, threshold = sklearn.metrics.roc_curve(test_2['label'], score[:,1])
auc = sklearn.metrics.roc_auc_score(test_2['label'], score[:,1])

fpr_list.append(fpr)
tpr_list.append(tpr)
threshold_list.append(threshold)
auc_list.append(auc)

optimal_threshold_list = []

for i in range(4):
  optimal_idx = np.argmax(tpr_list[i] - fpr_list[i])
  optimal_threshold = threshold_list[i][optimal_idx]
  optimal_threshold_list.append(optimal_threshold)

optimal_idx_list = []

for i in range(4):
  optimal_idx = np.argmax(tpr_list[i] - fpr_list[i])
  optimal_idx_list.append(optimal_idx)

name_list = ["LDA","Log-Reg","QDA","Rand-Forest"]
color_list = ["blue","green","gold","brown"]
plt.figure(figsize=(18,4))


plt.subplot(141)
plt.bar(name_list,optimal_threshold_list, color=color_list, alpha = 0.8)
plt.title("Threshold")

plt.subplot(142)
for i in range(4):
  plt.plot(fpr_list[i],tpr_list[i],label=name_list[i], c=color_list[i])
  plt.scatter(fpr_list[i][optimal_idx_list[i]],tpr_list[i][optimal_idx_list[i]],marker='o', c=color_list[i])
plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('ROC curve')
plt.legend(loc='best')
plt.plot([0, 1], [0, 1], '--')

plt.subplot(143)
for i in range(4):
  plt.plot(fpr_list[i],tpr_list[i],label=name_list[i], c=color_list[i])
  plt.scatter(fpr_list[i][optimal_idx_list[i]],tpr_list[i][optimal_idx_list[i]],marker='o', c=color_list[i])
plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.ylim(0.8,1.0)
plt.xlim(0,0.2)
plt.title('ROC curve zoomed in')
plt.legend(loc='best')

plt.subplot(144)
plt.bar(name_list,auc_list, color=color_list, alpha = 0.8)
plt.title("AUC score")
plt.ylim(0.94,1)


plt.subplots_adjust(wspace=0.25)

k = np.arange(1, 11)
model_name = ['Logistic', 'Random Forest', 'LDA', 'QDA']
def plot_loss(models, method):
  plt.figure(1)
  for i in range(len(models)):
    plt.plot(k, models[i]['loss'], label = model_name[i])
  plt.xlabel('Fold Used for Validation')
  plt.ylabel('Logistic Loss')
  plt.title('Logistic Loss of Models using split' + str(method))
  plt.legend()
  plt.ylim((0, 15))
  plt.figure(figsize=(12,10))
  plt.show()
plot_loss([log_1, rf_1, LDA_1, QDA_1], '1')

plot_loss([log_2, rf_2, LDA_2, QDA_2], '2')

"""## 3. Other Metric

### 1. F1 Score
"""

from sklearn.metrics import f1_score
def calculate_f1(models, train_feat, train_label, val_feat, val_label):
  f1_scores = []
  for model in models:
    model.fit(train_feat, train_label)
    y_score = model.predict(val_feat)
    f1_scores.append(f1_score(val_label, y_score, average='weighted'))
  return f1_scores

models = [
    sklearn.linear_model.LogisticRegression(),
    sklearn.ensemble.RandomForestClassifier(n_estimators=100,\
                                                  max_depth=20,\
                                                  random_state=0),\
    sklearn.discriminant_analysis.LinearDiscriminantAnalysis(),\
    sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis()
]
f1_scores = calculate_f1(models, train_feat_1[FEATURE], train_label_1, val_all_feat, val_all_labels)
f1_scores += calculate_f1(models, train_feat_2[FEATURE], train_label_2, val_all_feat, val_all_labels)

split_method = np.repeat(1, 4)
split_method = np.append(split_method, np.repeat(2, 4))

model_name = np.array(['Logistic','Random Forest','LDA', 'QDA', \
                       'Logistic','Random Forest','LDA', 'QDA'])

df = pd.DataFrame({'model': model_name,
                    'f1_score': f1_scores, 'split_method':split_method})
  
sns.set(style="whitegrid")
ax = sns.barplot(x="model", y="f1_score", hue = 'split_method', data=df)
ax.set_title('The Barplot of F1 Score of Each Classification Model')
ax.set_ylabel('F1 Score')
ax.set_xlabel('Model')

"""### 2. Log Loss"""

k = np.arange(1, 11)
model_name = ['Logistic', 'Random Forest', 'LDA', 'QDA']
def plot_loss(models, method):
  plt.figure(1)
  for i in range(len(models)):
    plt.plot(k, models[i]['loss'], label = model_name[i])
  plt.xlabel('Fold Used for Validation')
  plt.ylabel('Logistic Loss')
  plt.title('Logistic Loss of Models using split' + str(method))
  plt.legend()
  plt.ylim((0, 15))
  plt.figure(figsize=(12,10))
  plt.show()
plot_loss([log_1, rf_1, LDA_1, QDA_1], '1')

plot_loss([log_2, rf_2, LDA_2, QDA_2], '2')

"""# Section 4. Diagnostics

## 1. Random Forest Parameter Tuning
"""

from sklearn.model_selection import RandomizedSearchCV
# Number of trees in random forest
n_estimators = [int(x) for x in np.linspace(start = 100, stop = 120, num = 5)]

# Maximum number of levels in tree
max_depth = [int(x) for x in np.linspace(70, 110, num = 5)]

# Create the random grid
random_grid = {'n_estimators': n_estimators,
               'max_depth': max_depth}
print(random_grid)

rf = sklearn.ensemble.RandomForestClassifier()
grid_search = sklearn.model_selection.GridSearchCV(estimator = rf, param_grid = random_grid, 
                          cv = 2, n_jobs = -1, verbose = 2)
grid_search.fit(train_feat_2[FEATURE], train_label_2) # 15 70
#grid_search.fit(train_feat_1[FEATURE], train_label_1) # max_depth 30  n_estimators 70
grid_search.best_params_

grid_search.cv_results_

"""## 2. Misclassification Error"""

#Source:https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html#sphx-glr-auto-examples-model-selection-plot-learning-curve-py
def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,
                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):
  
    plt.figure()
    plt.title(title)
    if ylim is not None:
        plt.ylim(*ylim)
    plt.xlabel("Training examples")
    plt.ylabel("Score")
    train_sizes, train_scores, test_scores = learning_curve(
        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)
    train_scores_mean = np.mean(train_scores, axis=1)
    train_scores_std = np.std(train_scores, axis=1)
    test_scores_mean = np.mean(test_scores, axis=1)
    test_scores_std = np.std(test_scores, axis=1)
    plt.grid()

    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,
                     train_scores_mean + train_scores_std, alpha=0.1,
                     color="r")
    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,
                     test_scores_mean + test_scores_std, alpha=0.1, color="g")
    plt.plot(train_sizes, train_scores_mean, 'o-', color="r",
             label="Training score")
    plt.plot(train_sizes, test_scores_mean, 'o-', color="g",
             label="Cross-validation score")

    plt.legend(loc="best")
    return plt

from sklearn.model_selection import learning_curve
estimator = sklearn.ensemble.RandomForestClassifier(n_estimators = 100, max_depth = 20)

title_2 = r"Learning Curves (Random Forest) using split2"
X = train_feat_2[FEATURE]
y = train_label_2
plot_learning_curve(estimator, title_2, X, y, ylim=(0.6, 1.01), cv=10, n_jobs=-1)

title_1 = r"Learning Curves (Random Forest) using split1"
X = train_feat_1[FEATURE]
y = train_label_1
plot_learning_curve(estimator, title_1, X, y, ylim=(0.6, 1.01), cv=10, n_jobs=-1)

"""# Section 5. Bancroft Model"""

img1_raw = pd.read_csv("./img1.csv", index_col=0)
img2_raw = pd.read_csv("./img2.csv", index_col=0)
img3_raw = pd.read_csv("./img3.csv", index_col=0)

col_names = ['x', 'y', 'label', 'NDAI', 'SD', 'CORR','DF','CF','BF','AF','AN']
img1_raw.columns = col_names
img2_raw.columns = col_names
img3_raw.columns = col_names

def get_neighbor_feature(curr_x, curr_y, low_x, high_x, low_y, high_y, img):
  next_corr, next_ndai, next_sd = 0.0, 0.0, 0.0
  count = 0
  for i in range(-1, 2, 1):
    for j in range(-1, 2, 1):
      if i == 0 and j == 0:
        continue
      next_x, next_y = curr_x + i, curr_y + j
      if next_x < low_x or next_x > high_x or next_y < low_y or next_y > high_y:
        continue
      neighbor_pixel = img[(img['x'] == next_x) & (img['y'] == next_y)]
      if not neighbor_pixel.empty:
        next_corr += neighbor_pixel.iloc[0]['CORR']
        next_ndai += neighbor_pixel.iloc[0]['NDAI']
        next_sd += neighbor_pixel.iloc[0]['SD']
        count += 1
  if count == 0:
    return (0,0,0)
  return (next_corr/count, next_ndai/count, next_sd/count)

def add_new_features(img):
  neighbor_corr, neighbor_ndai, neighbor_sd = [],[],[]
  low_x, high_x = min(img['x']), max(img['x'])
  low_y, high_y = min(img['y']), max(img['y'])
  
  for i in range(len(img)):
    curr_row = img.iloc[i]
    curr_x, curr_y = curr_row['x'], curr_row['y']
    if curr_row['label'] == 0:
      mean_corr, mean_ndai, mean_sd = (0,0,0)
    else:
      mean_corr, mean_ndai, mean_sd = get_neighbor_feature(curr_x, curr_y, \
                                                         low_x, high_x, \
                                                         low_y, high_y, \
                                                         img)
    neighbor_corr.append(mean_corr)
    neighbor_ndai.append(mean_ndai)
    neighbor_sd.append(mean_sd)
 
  img['Neighbor CORR'] = neighbor_corr
  img['Neighbor NDAI'] = neighbor_ndai
  img['Neighbor SD'] = neighbor_sd
  return img

img1_added = add_new_features(img1_raw)
img1_added = img1_added[img1_added['label'] != 0.0]

img2_added = add_new_features(img2_raw)
img2_added = img2_added[img2_added['label'] != 0.0]

img3_added = add_new_features(img3_raw)
img3_added = img3_added[img3_added['label'] != 0.0]

img1.shape[0]

img2.shape[0]

img3.shape[0]

"""## Bancroft Model Analysis"""

img1_added['tag'] = 'img1' 
img2_added['tag'] = 'img2'
img3_added['tag'] = 'img3'

data_combined = pd.concat([img1_added, img2_added])
data_combined = pd.concat([data_combined, img3_added])
data_combined.index = range(len(data_combined))
data_combined.to_csv('./data_combined.csv')

combined_train_1, combined_valid_1, combined_test_1 = split1(data_combined)

combined_train_1 = combined_train_1.sample(frac=1)
combined_test_1 = combined_test_1.sample(frac=1)
combined_valid_1 = combined_valid_1.sample(frac=1)

combined_train_2 = pd.concat([img1_added.iloc[:int(len(img1_added) * 0.6) , ],
                             img2_added.iloc[:int(len(img2_added) * 0.6) , ]])

combined_train_2 = pd.concat([combined_train_2, \
                              img3_added.iloc[:int(len(img3_added) * 0.6), ]])


combined_valid_2 = pd.concat([img1_added.iloc[int(len(img1_added)* 0.6):int(len(img1_added)* 0.8), ],
                             img2_added.iloc[int(len(img2_added)* 0.6):int(len(img2_added)* 0.8), ]])

combined_valid_2 = pd.concat([combined_valid_2, 
                              img3_added.iloc[int(len(img3_added)* 0.6):int(len(img3_added)* 0.8), ]])

combined_test_2 = pd.concat([img1_added.iloc[int(len(img1_added)* 0.8):, ],
                             img2_added.iloc[int(len(img2_added)* 0.8):, ]])
combined_test_2 = pd.concat([combined_test_2, \
                             img3_added.iloc[int(len(img3_added)* 0.8):, ]])

combined_train_2.to_csv('./combined_train_2.csv')
combined_valid_2.to_csv('./combined_valid_2.csv')
combined_test_2.to_csv('./combined_test_2.csv')

len(combined_test_2[combined_test_2['tag'] =='img3'])

len(combined_valid_2[combined_valid_2['tag'] =='img3'])

len(combined_train_2[combined_train_2['tag'] =='img3'])

combined_valid_all = pd.concat([combined_valid_1, combined_valid_2])
combined_valid_all.drop_duplicates(subset = ['x', 'y', 'SD', 'NDAI','AF'], 
                     keep = 'first', inplace = True)

combined_test_all = pd.concat([combined_test_1, combined_test_2])
combined_test_all.drop_duplicates(subset = ['x', 'y', 'SD', 'NDAI','AF'], 
                     keep = 'first', inplace = True)

RANDOM_SEED = 2019
estimator_1 = sklearn.ensemble.RandomForestClassifier(n_estimators = 200, \
                                                      max_depth = 30, \
                                                      min_samples_split = 300,
                                                      max_features = 11, 
                                                     random_state = RANDOM_SEED)

estimator_2 = sklearn.ensemble.RandomForestClassifier(n_estimators = 100, \
                                                      max_depth = 20, \
                                                      min_samples_split = 300,
                                                      max_features = 11,
                                                     random_state = RANDOM_SEED)

NEW_FEATURE = ['CORR','NDAI','SD','BF','DF', 'CF', 'AF','AN','Neighbor CORR',\
                'Neighbor NDAI','Neighbor SD']
estimator_1.fit(combined_train_1[NEW_FEATURE], combined_train_1['label'])

estimator_2.fit(combined_train_2[NEW_FEATURE], combined_train_2['label'])

pred_1 = estimator_1.predict(combined_valid_1[NEW_FEATURE])
print('Estimator 1 on valid_1: ' + str(np.mean(pred_1 == combined_valid_1['label'])))

pred_test_1 = estimator_1.predict(combined_test_1[NEW_FEATURE])
print('Estimator 1 on test_1: ' + str(np.mean(pred_test_1 == combined_test_1['label'])))

pred_valid_1 = estimator_1.predict(combined_valid_all[NEW_FEATURE])
print('Estimator 1 on valid_all: ' + str(np.mean(pred_valid_1 == combined_valid_all['label'])))
      
pred_test_1 = estimator_1.predict(combined_test_all[NEW_FEATURE])
print('Estimator 1 on test_all: ' + str(np.mean(pred_test_1 == combined_test_all['label'])))

pred_2 = estimator_2.predict(combined_valid_2[NEW_FEATURE])
print('Estimator 2 on valid_2: ' + str(np.mean(pred_2 == combined_valid_2['label'])))

pred_test_2 = estimator_2.predict(combined_test_2[NEW_FEATURE])
print('Estimator 2 on test_2: ' + str(np.mean(pred_test_2 == combined_test_2['label'])))

pred_valid_all_2 = estimator_2.predict(combined_valid_all[NEW_FEATURE])
print('Estimator 2 on valid_all: ' + str(np.mean(pred_valid_all_2 == combined_valid_all['label'])))
      
pred_test_all_2 = estimator_2.predict(combined_test_all[NEW_FEATURE])
print('Estimator 2 on test_all: ' + str(np.mean(pred_test_all_2 == combined_test_all['label'])))

importances = estimator_2.feature_importances_
indices = np.argsort(importances)
plt.figure(figsize=(5,5))
plt.title('Feature Importances')
plt.barh(range(len(indices)), importances[indices], color='blue', align='center')
plt.yticks(range(len(indices)), [NEW_FEATURE[i] for i in indices])
plt.xlabel('Relative Importance')

"""## Experiment

### Run Train1 on new feature
"""

comb_model_1 = sklearn.ensemble.RandomForestClassifier(n_estimators=200, max_depth=20,
                                                    max_features=11, random_state=RANDOM_SEED,
                                                    min_samples_split = 300)
comb_model_1.fit(comb_train_1[FEATURE],comb_train_1["label"])

# Predict Validation
comb_val_hat = comb_model_1.predict(combined_valid_all[FEATURE])
print(np.mean(comb_val_hat == combined_valid_all['label']))
comb_false_classified = combined_valid_all[comb_val_hat != combined_valid_all['label']]
comb_correct_classified = combined_valid_all[comb_val_hat == combined_valid_all['label']]

# Predict test_all
comb_test_hat = comb_model_1.predict(combined_test_all[FEATURE])
print(np.mean(comb_test_hat == combined_test_all['label']))
comb_false_classified = combined_test_all[comb_test_hat != combined_test_all['label']]
comb_correct_classified = combined_test_all[comb_test_hat == combined_test_all['label']]

# Predict test_1
comb_test_hat = comb_model_1.predict(comb_test_1[FEATURE])
print(np.mean(comb_test_hat == comb_test_1['label']))
comb_false_classified = comb_test_1[comb_test_hat != comb_test_1['label']]
comb_correct_classified = comb_test_1[comb_test_hat == comb_test_1['label']]

# Predict all pixels
comb_all_hat = comb_model_1.predict(data_combined[FEATURE])
print(np.mean(comb_all_hat == data_combined['label']))
comb_false_classified = data_combined[comb_all_hat != data_combined['label']]
comb_correct_classified = data_combined[comb_all_hat == data_combined['label']]

bins = [np.linspace(0,400,10),
        np.linspace(100,400,10),
        np.linspace(-2,4,10),
       np.linspace(0,0.8,10),
       np.linspace(0,75,10)]

plt.figure(figsize=(16,3))

for i,name in enumerate(['x','y','NDAI','CORR','SD']):
  plt.subplot(1,5,1+i)
  plt.hist(comb_false_classified[name],bins[i], density = True, label = "Incorrect", alpha = 0.8, color='blue')
  plt.hist(comb_correct_classified[name], bins[i], density = True, label="Correct", alpha = 0.8, color='orange')
  plt.legend()
  plt.axvline(x=np.mean(comb_false_classified[name]),c='blue')
  plt.axvline(x=np.mean(comb_correct_classified[name]),c='orange')
  plt.title(name)
plt.subplots_adjust(wspace=0.3)

comb_img1_misclassified = comb_false_classified[comb_false_classified['tag'] == 'img1']
comb_img2_misclassified = comb_false_classified[comb_false_classified['tag'] == 'img2']
comb_img3_misclassified = comb_false_classified[comb_false_classified['tag'] == 'img3']

plt.figure(figsize=(15,5))

plt.subplot(1,3,1)
plt.imshow(img1_pad,cmap="Blues", origin='lower')
plt.scatter(comb_img1_misclassified['y'],comb_img1_misclassified['x'],c='brown',marker='x',s=0.5)
plt.title("Image 1")

plt.subplot(1,3,2)
plt.imshow(img2_pad,cmap="Blues",origin='lower')
plt.scatter(comb_img2_misclassified['y'],comb_img2_misclassified['x'],c='brown',marker='x', s=0.5)
plt.title("Image 2")

plt.subplot(1,3,3)
plt.imshow(img3_pad,cmap="Blues",origin='lower')
plt.scatter(comb_img3_misclassified['y'], comb_img3_misclassified['x'],c='brown',marker='x', s=0.5)
plt.title("Image 3")

importances = comb_model_1.feature_importances_
indices = np.argsort(importances)
plt.figure(figsize=(5,5))
plt.title('Feature Importances')
plt.barh(range(len(indices)), importances[indices], color='blue', align='center')
plt.yticks(range(len(indices)), [FEATURE[i] for i in indices])
plt.xlabel('Relative Importance')

"""### Run train 2 on new feature"""

FEATURE

comb_model_2 = sklearn.ensemble.RandomForestClassifier(n_estimators=50, max_depth=10,
                                                    max_features=11, random_state=2019,
                                                    min_samples_split = 300)
comb_model_2.fit(combined_train_2[FEATURE], combined_train_2["label"])

# Predict Validation
comb_val_hat = comb_model_2.predict(combined_valid_all[FEATURE])
print(np.mean(comb_val_hat == combined_valid_all['label']))
comb_false_classified = combined_valid_all[comb_val_hat != combined_valid_all['label']]
comb_correct_classified = combined_valid_all[comb_val_hat == combined_valid_all['label']]

# # Predict Validation
# comb_val_hat = comb_model_2.predict(combined_valid_2[FEATURE])
# print(np.mean(comb_val_hat == combined_valid_2['label']))
# comb_false_classified = combined_valid_2[comb_val_hat != combined_valid_2['label']]
# comb_correct_classified = combined_valid_2[comb_val_hat == combined_valid_2['label']]

# # Predict test
# comb_test_hat = comb_model_2.predict(combined_test_all[FEATURE])
# print(np.mean(comb_test_hat == combined_test_all['label']))
# comb_false_classified = combined_test_all[comb_test_hat != combined_test_all['label']]
# comb_correct_classified = combined_test_all[comb_test_hat == combined_test_all['label']]

# # Predict all pixels
# comb_all_hat = comb_model_2.predict(data_combined[FEATURE])
# print(np.mean(comb_all_hat == data_combined['label']))
# comb_false_classified = data_combined[comb_all_hat != data_combined['label']]
# comb_correct_classified = data_combined[comb_all_hat == data_combined['label']]

bins = [np.linspace(0,400,10),
        np.linspace(100,400,10),
        np.linspace(-2,4,10),
       np.linspace(0,0.8,10),
       np.linspace(0,75,10)]

plt.figure(figsize=(16,3))

for i,name in enumerate(['x','y','NDAI','CORR','SD']):
  plt.subplot(1,5,1+i)
  plt.hist(comb_false_classified[name],bins[i], density = True, label = "Incorrect", alpha = 0.8, color='blue')
  plt.hist(comb_correct_classified[name], bins[i], density = True, label="Correct", alpha = 0.8, color='orange')
  plt.legend()
  plt.axvline(x=np.mean(comb_false_classified[name]),c='blue')
  plt.axvline(x=np.mean(comb_correct_classified[name]),c='orange')
  plt.title(name)
plt.subplots_adjust(wspace=0.3)

comb_img1_misclassified = comb_false_classified[comb_false_classified['tag'] == 'img1']
comb_img2_misclassified = comb_false_classified[comb_false_classified['tag'] == 'img2']
comb_img3_misclassified = comb_false_classified[comb_false_classified['tag'] == 'img3']

plt.figure(figsize=(15,5))

plt.subplot(1,3,1)
plt.imshow(img1_pad,cmap="Blues", origin='lower')
plt.scatter(comb_img1_misclassified['y'],comb_img1_misclassified['x'],c='brown',marker='x',s=0.5)
plt.title("Image 1")

plt.subplot(1,3,2)
plt.imshow(img2_pad,cmap="Blues",origin='lower')
plt.scatter(comb_img2_misclassified['y'],comb_img2_misclassified['x'],c='brown',marker='x', s=0.5)
plt.title("Image 2")

plt.subplot(1,3,3)
plt.imshow(img3_pad,cmap="Blues",origin='lower')
plt.scatter(comb_img3_misclassified['y'], comb_img3_misclassified['x'],c='brown',marker='x', s=0.5)
plt.title("Image 3")

importances = comb_model.feature_importances_
indices = np.argsort(importances)
plt.figure(figsize=(5,5))
plt.title('Feature Importances')
plt.barh(range(len(indices)), importances[indices], color='blue', align='center')
plt.yticks(range(len(indices)), [FEATURE[i] for i in indices])
plt.xlabel('Relative Importance')

"""# Appendix

## A. Create Padding for `plt.imshow`

Padding for NDAI
"""

# Create Padding for imshow()

img3_pad_ndai = np.zeros((384,384))
for i in img3.index:
  img3_pad_ndai[int(img3.loc[i]['x']),int(img3.loc[i]['y'])] = img3.loc[i]['NDAI']

img2_pad_ndai = np.zeros((384,384))
for i in img2.index:
  img2_pad_ndai[int(img2.loc[i]['x']),int(img2.loc[i]['y'])] = img2.loc[i]['NDAI']

img1_pad_ndai = np.zeros((384,384))
for i in img1.index:
  img1_pad_ndai[int(img1.loc[i]['x']),int(img1.loc[i]['y'])] = img1.loc[i]['NDAI']

np.save("./img1_pad_ndai.npy",img1_pad_ndai)
np.save("./img2_pad_ndai.npy",img2_pad_ndai)
np.save("./img3_pad_ndai.npy",img3_pad_ndai)

"""Padding for SD"""

# Create Padding for imshow()

img3_pad_sd = np.zeros((384,384))
for i in img3.index:
  img3_pad_sd[int(img3.loc[i]['x']),int(img3.loc[i]['y'])] = img3.loc[i]['SD']

img2_pad_sd = np.zeros((384,384))
for i in img2.index:
  img2_pad_sd[int(img2.loc[i]['x']),int(img2.loc[i]['y'])] = img2.loc[i]['SD']

img1_pad_sd = np.zeros((384,384))
for i in img1.index:
  img1_pad_sd[int(img1.loc[i]['x']),int(img1.loc[i]['y'])] = img1.loc[i]['SD']

np.save("./img1_pad_sd.npy",img1_pad_sd)
np.save("./img2_pad_sd.npy",img2_pad_sd)
np.save("./img3_pad_sd.npy",img3_pad_sd)

"""corr Filter"""

# Create Padding for imshow()

img3_pad_corr = np.zeros((384,384))
for i in img3.index:
  img3_pad_corr[int(img3.loc[i]['x']),int(img3.loc[i]['y'])] = img3.loc[i]['CORR']

img2_pad_corr = np.zeros((384,384))
for i in img2.index:
  img2_pad_corr[int(img2.loc[i]['x']),int(img2.loc[i]['y'])] = img2.loc[i]['CORR']

img1_pad_corr = np.zeros((384,384))
for i in img1.index:
  img1_pad_corr[int(img1.loc[i]['x']),int(img1.loc[i]['y'])] = img1.loc[i]['CORR']

np.save("./img1_pad_corr.npy",img1_pad_corr)
np.save("./img2_pad_corr.npy",img2_pad_corr)
np.save("./img3_pad_corr.npy",img3_pad_corr)